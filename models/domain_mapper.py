"""
Train state mappings with dht models.
"""

import os
import sys
from pathlib import Path

import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset
from torch.nn import MSELoss
import pytorch_lightning as pl
from pytorch_lightning.trainer.supporters import CombinedLoader
from torch.optim.lr_scheduler import ReduceLROnPlateau
from models.trajectory_encoder import TrajectoryEncoder

sys.path.append(str(Path(__file__).resolve().parents[1]))

from utils.nn import KinematicChainLoss, create_network
from utils.soft_dtw_cuda import SoftDTW
from models.dht import get_dht_model
from itertools import chain

from config import data_folder


class LitDomainMapper(pl.LightningModule):
    def __init__(self,
                 data_file_A, data_file_B,
                 transition_model_config={},
                 state_mapper_config={},
                 action_mapper_config={},
                 batch_size=32,
                 num_workers=1,
                 components=["s", "a", "t"],
                 weight_matrix_exponent=np.inf,
                 **kwargs
                 ):
        super(LitDomainMapper, self).__init__()

        self.save_hyperparameters()

        self.dht_model_A, self.transition_model_A, self.state_mapper_AB, self.trajectory_encoder_AZ, self.policy_ZA = \
            self.get_models(data_file_A, data_file_B, transition_model_config, state_mapper_config,
                            action_mapper_config)
        self.dht_model_B, self.transition_model_B, self.state_mapper_BA, self.trajectory_encoder_BZ, self.policy_ZB = \
            self.get_models(data_file_B, data_file_A, transition_model_config, state_mapper_config,
                            action_mapper_config)

        self.loss_fn_transition_model, \
        self.loss_fn_kinematics_AB, self.loss_fn_kinematics_BA, self.loss_fn_soft_dtw_AB, \
        self.loss_fn_soft_dtw_BA = self.get_loss_functions()

        self.configure_components(components)

        # manual optimization in training_step
        self.automatic_optimization = False

    def configure_components(self, components):
        self.relevant_optimizers = set()

        if "t" in components:
            self.relevant_optimizers.update([0, 1])
        if "s" in components:
            self.relevant_optimizers.update([2, 3])
        if "a" in components:
            self.relevant_optimizers.update([4, 5])

    def forward(self, states_A):
        """
            Maps states and actions A -> B
            Required by super class LightningModule

            Args:
                state_A
                action_A
            Returns:
                Mapped state and action
        """

        with torch.no_grad():
            states_B_ = self.state_mapper_AB.get_dummB_tgt(states_A)

            for _ in range(states_B_.shape[-1] - 1):
                states_B = self.state_mapper_AB(states_A, states_B_)
                states_B_ = torch.nn.functional.pad(states_B[:, :-1], (1, 0), mode="constant", value=torch.nan)

        states_B = self.state_mapper_AB(states_A, states_B_)

        return states_B

    def get_models(self, data_file_X, data_file_Y, transition_model_config, state_mapper_config, action_mapper_config):
        """
            Helper function to generate all models required to learn mapping X -> Y

            Args:
                data_file_X, data_file_Y: Data files for both domains generated by 01_generate_data.py
                {transition_model, state_mapper, action_mapper}_{network_width, network_depth, dropout}:
                    Hyperparameters for neural networks

            Returns:
                Pytorch models according to specified hyperparameters
        """

        data_path_X = os.path.join(data_folder, data_file_X)
        data_X = torch.load(data_path_X)

        data_path_Y = os.path.join(data_folder, data_file_Y)
        data_Y = torch.load(data_path_Y)

        dht_model_X = get_dht_model(data_X["dht_params"], data_X["joint_limits"])

        transition_model_X = create_network(
            in_dim=data_X["trajectories_states_train"].shape[-1] + data_X["trajectories_actions_train"].shape[-1],
            out_dim=data_X["trajectories_states_train"].shape[-1],
            **transition_model_config,
        )

        state_mapper_XY = create_network(
            in_dim=data_X["trajectories_states_train"].shape[-1],
            out_dim=data_Y["trajectories_states_train"].shape[-1],
            **state_mapper_config,
        )

        trajectory_encoder_XZ = TrajectoryEncoder(
            state_dim=data_X["trajectories_states_train"].shape[-1],
            action_dim=data_X["trajectories_actions_train"].shape[-1],
            behavior_dim=action_mapper_config["behavior_dim"],
            max_len=data_X["trajectories_states_train"].shape[-1] + data_X["trajectories_actions_train"].shape[-1],
            **action_mapper_config["encoder"]
        )

        policy_ZX = create_network(
            in_dim=data_X["trajectories_states_train"].shape[-1] + action_mapper_config["behavior_dim"],
            out_dim=data_X["trajectories_actions_train"].shape[-1],
            **action_mapper_config["decoder"]
        )

        return dht_model_X, transition_model_X, state_mapper_XY, trajectory_encoder_XZ, policy_ZX

    def get_loss_functions(self):
        """
            Helper function to generate all loss functions

            Returns:
                Loss functions
        """

        data_path_A = os.path.join(data_folder, self.hparams.data_file_A)
        data_A = torch.load(data_path_A)

        data_path_B = os.path.join(data_folder, self.hparams.data_file_B)
        data_B = torch.load(data_path_B)

        loss_fn_transition_model = MSELoss()

        link_positions_A = self.dht_model_A(torch.zeros((1, data_A["trajectories_states_train"].shape[-1])))[0, :, :3,
                           -1]
        link_positions_B = self.dht_model_B(torch.zeros((1, data_B["trajectories_states_train"].shape[-1])))[0, :, :3,
                           -1]

        weight_matrix_AB_p, weight_matrix_AB_o = self.get_weight_matrices(link_positions_A, link_positions_B,
                                                                          self.hparams.weight_matrix_exponent)

        loss_fn_kinematics_AB = KinematicChainLoss(weight_matrix_AB_p, weight_matrix_AB_o, verbose_output=True)
        loss_fn_kinematics_BA = KinematicChainLoss(weight_matrix_AB_p.T, weight_matrix_AB_o.T, verbose_output=True)

        loss_soft_dtw_AB = SoftDTW(use_cuda=True,
                                   dist_func=KinematicChainLoss(weight_matrix_AB_p, weight_matrix_AB_o,
                                                                reduction=False))
        loss_soft_dtw_BA = SoftDTW(use_cuda=True,
                                   dist_func=KinematicChainLoss(weight_matrix_AB_p.T, weight_matrix_AB_o.T,
                                                                reduction=False))

        return loss_fn_transition_model, loss_fn_kinematics_AB, loss_fn_kinematics_BA, loss_soft_dtw_AB, loss_soft_dtw_BA

    @staticmethod
    def get_weight_matrices(link_positions_X, link_positions_Y, weight_matrix_exponent_p, norm=True):
        """
            Generate weights based on distances between relative positions of robot links

            Params:
                link_positions_{X, Y}: Positions of both robots in 3D space.
                weight_matrix_exponent_p: Parameter used to shape the position weight matrix by emphasizing similarity.
                    weight = exp(-weight_matrix_exponent_p * distance)

            Returns:
                weight_matrix_XY_p: Weight matrix for positions
                weight_matrix_XY_p: Weight matrix for orientations. All zeros except weight which corresponds to the end effectors.
        """

        link_positions_X = torch.cat((torch.zeros(1, 3), link_positions_X))
        link_lenghts_X = torch.norm(link_positions_X[1:] - link_positions_X[:-1], p=2, dim=-1)
        link_order_X = link_lenghts_X.cumsum(0)
        link_order_X = link_order_X / link_order_X[-1]

        link_positions_Y = torch.cat((torch.zeros(1, 3), link_positions_Y))
        link_lenghts_Y = torch.norm(link_positions_Y[1:] - link_positions_Y[:-1], p=2, dim=-1)
        link_order_Y = link_lenghts_Y.cumsum(0)
        link_order_Y = link_order_Y / link_order_Y[-1]

        weight_matrix_XY_p = torch.exp(
            -weight_matrix_exponent_p * torch.cdist(link_order_X.unsqueeze(-1), link_order_Y.unsqueeze(-1)))
        weight_matrix_XY_p = torch.nan_to_num(weight_matrix_XY_p, 1.)

        weight_matrix_XY_o = torch.zeros(len(link_positions_X), len(link_positions_Y))
        weight_matrix_XY_o[-1, -1] = 1

        if norm:
            weight_matrix_XY_p /= weight_matrix_XY_p.sum()
            weight_matrix_XY_o /= weight_matrix_XY_o.sum()

        return weight_matrix_XY_p, weight_matrix_XY_p

    def get_train_dataloader(self, data_file):
        data_path = os.path.join(data_folder, data_file)
        data = torch.load(data_path)

        trajectories_states_train = data["trajectories_states_train"].float()
        trajectories_actions_train = data["trajectories_actions_train"].float()

        dataloader_train = DataLoader(TensorDataset(trajectories_states_train, trajectories_actions_train),
                                      batch_size=self.hparams.batch_size, num_workers=self.hparams.num_workers,
                                      shuffle=True, pin_memory=True)

        return dataloader_train

    def get_validation_dataloader(self, data_file):
        data_path = os.path.join(data_folder, data_file)
        data = torch.load(data_path)

        trajectories_states_test = data["trajectories_states_test"].float()
        trajectories_actions_test = data["trajectories_actions_test"].float()

        dataloader_validation = DataLoader(TensorDataset(trajectories_states_test, trajectories_actions_test),
                                           batch_size=self.hparams.batch_size, num_workers=self.hparams.num_workers,
                                           pin_memory=True)

        return dataloader_validation

    def train_dataloader(self):
        """
            Generate dataloader used for training.
            Refer to pytorch lightning docs.
        """

        dataloader_train_A = self.get_train_dataloader(self.hparams.data_file_A)
        dataloader_train_B = self.get_train_dataloader(self.hparams.data_file_B)
        return CombinedLoader({"A": dataloader_train_A, "B": dataloader_train_B})

    def val_dataloader(self):
        """
            Generate dataloader used for validation.
            Refer to pytorch lightning docs.
        """

        dataloader_validation_A = self.get_validation_dataloader(self.hparams.data_file_A)
        dataloader_validation_B = self.get_validation_dataloader(self.hparams.data_file_B)

        return CombinedLoader({"A": dataloader_validation_A, "B": dataloader_validation_B})

    def loss_transition_model(self, batch, transition_model, loss_fn):
        """
            Determine loss of transition model on batch.
        """

        trajectories_states, trajectories_actions = batch

        states = trajectories_states[:,:-1].reshape(-1, trajectories_states.shape[-1])
        next_states = trajectories_states[:,:-1].reshape(-1, trajectories_states.shape[-1])

        actions = trajectories_actions.reshape(-1, trajectories_actions.shape[-1])

        states_actions = torch.concat((states, actions), axis=-1)
        next_states_predicted = transition_model(states_actions)
        loss_transition_model = loss_fn(next_states_predicted, next_states)
        return loss_transition_model

    def loss_state_mapper(self, batch, state_mapper_XY, dht_model_X, dht_model_Y, loss_fn):
        """
            Determine loss of state mapper on batch.
        """

        trajectories_states_X, _ = batch

        states_X = trajectories_states_X.reshape(-1, trajectories_states_X.shape[-1])

        states_Y = state_mapper_XY(states_X)

        link_poses_X = dht_model_X(states_X)
        link_poses_Y = dht_model_Y(states_Y)

        loss_state_mapper_XY, loss_state_mapper_XY_p, loss_state_mapper_XY_o = loss_fn(link_poses_X, link_poses_Y)

        return loss_state_mapper_XY, loss_state_mapper_XY_p, loss_state_mapper_XY_o

    def loss_action_mapper(self, batch, trajectory_encoder_XZ, policy_ZY, state_mapper_XY, dht_model_X, dht_model_Y,
                           transition_model_Y, loss_fn):
        """
            Determine loss of action mapper on batch.
        """

        # bls, bla
        trajectories_states_X, trajectories_actions_X = batch

        # bz
        behaviors = trajectory_encoder_XZ(trajectories_states_X, trajectories_actions_X)

        trajectories_states_Y = []

        # bs
        states_Y = state_mapper_XY(trajectories_states_X[:, 0])
        trajectories_states_Y.append(states_Y)

        for step in range(trajectories_actions_X.shape[1]):
            # b(s+z)
            states_Y_behaviors = torch.concat((states_Y, behaviors), dim=-1)

            # ba
            actions_Y = policy_ZY(states_Y_behaviors)
            # b(s+a)
            states_actions_Y = torch.concat((states_Y, actions_Y), dim=-1)
            # bs
            states_Y = transition_model_Y(states_actions_Y)

            trajectories_states_Y.append(states_Y)

        # bls
        trajectories_states_Y = torch.stack(trajectories_states_Y).swapdims(0, 1)

        # (b*l)s
        states_X = trajectories_states_X.reshape(-1, trajectories_states_X.shape[-1])
        states_Y = trajectories_states_Y.reshape(-1, trajectories_states_Y.shape[-1])

        # (b*l)p44
        link_poses_X = dht_model_X(states_X)
        link_poses_Y = dht_model_Y(states_Y)

        # blp44
        link_poses_X = link_poses_X.reshape(*trajectories_states_X.shape[:2], *link_poses_X.shape[1:])
        link_poses_Y = link_poses_Y.reshape(*trajectories_states_Y.shape[:2], *link_poses_Y.shape[1:])

        loss = loss_fn(link_poses_X, link_poses_Y).mean()

        return loss

    # def training_epoch_end(self, outputs) -> None:
    #     self.log("growth", self.growth_fn(self.current_epoch))

    def training_step(self, batch, batch_idx):
        """
            Perform training step. Customized behavior to enable accumulation of all losses into one variable.
            Refer to pytorch lightning docs.
        """

        cumulated_loss = 0.

        for optimizer_idx, optimizer in enumerate(self.optimizers()):
            if not optimizer_idx in self.relevant_optimizers:
                continue

            optimizer.zero_grad()
            loss = self.step(batch, batch_idx, optimizer_idx, "train_")
            self.manual_backward(loss)
            optimizer.step()

            cumulated_loss += loss.item()

        self.log("train_loss", cumulated_loss, on_step=False, on_epoch=True)

    def training_epoch_end(self, outputs):
        super(LitDomainMapper, self).training_epoch_end(outputs)

        self.log("debug_id", self.debug_id, on_epoch=True)

    def validation_step(self, batch, batch_idx):
        """
            Perform validation step. Customized behavior to enable accumulation of all losses into one variable.
            Refer to pytorch lightning docs.
        """

        cumulated_loss = 0.

        for optimizer_idx in range(len(self.optimizers())):
            if not optimizer_idx in self.relevant_optimizers:
                continue

            loss = self.step(batch, batch_idx, optimizer_idx, "validation_")
            cumulated_loss += loss.item()

        self.log("validation_loss", cumulated_loss, on_step=False, on_epoch=True)

    def step(self, batch, batch_idx, optimizer_idx, log_prefix=""):
        """
            Perform one step (compute loss) for a model corresponding to an optimizer_idx.

            Params:
                batch: data
                batch_idx: not used
                optimizer_idx: Optimizer (and respective model) to evaluate
                log_prefix: used to log training and validation losses under different names

            Returns:
                loss
        """

        if optimizer_idx == 0:
            loss_transition_model = self.loss_transition_model(batch["A"], self.transition_model_A,
                                                               self.loss_fn_transition_model)
            self.log(log_prefix + 'loss_transition_model_A', loss_transition_model, on_step=False, on_epoch=True)
            return loss_transition_model
        elif optimizer_idx == 1:
            loss_transition_model = self.loss_transition_model(batch["B"], self.transition_model_B,
                                                               self.loss_fn_transition_model)
            self.log(log_prefix + 'loss_transition_model_B', loss_transition_model, on_step=False, on_epoch=True)
            return loss_transition_model
        elif optimizer_idx == 2:
            loss_state_mapper, loss_state_mapper_p, loss_state_mapper_o = self.loss_state_mapper(batch["A"],
                                                                                                 self.state_mapper_AB,
                                                                                                 self.dht_model_A,
                                                                                                 self.dht_model_B,
                                                                                                 self.loss_fn_kinematics_AB)
            self.log(log_prefix + 'loss_state_mapper_AB', loss_state_mapper, on_step=False, on_epoch=True)
            self.log(log_prefix + 'loss_state_mapper_AB_p', loss_state_mapper_p, on_step=False, on_epoch=True)
            self.log(log_prefix + 'loss_state_mapper_AB_o', loss_state_mapper_o, on_step=False, on_epoch=True)
            return loss_state_mapper
        elif optimizer_idx == 3:
            loss_state_mapper, loss_state_mapper_p, loss_state_mapper_o = self.loss_state_mapper(batch["B"],
                                                                                                 self.state_mapper_BA,
                                                                                                 self.dht_model_B,
                                                                                                 self.dht_model_A,
                                                                                                 self.loss_fn_kinematics_BA)
            self.log(log_prefix + 'loss_state_mapper_BA', loss_state_mapper, on_step=False, on_epoch=True)
            self.log(log_prefix + 'loss_state_mapper_BA_p', loss_state_mapper_p, on_step=False, on_epoch=True)
            self.log(log_prefix + 'loss_state_mapper_BA_o', loss_state_mapper_o, on_step=False, on_epoch=True)
            return loss_state_mapper
        elif optimizer_idx == 4:
            loss_action_mapper = self.loss_action_mapper(batch["A"], self.trajectory_encoder_AZ, self.policy_ZB,
                                                         self.state_mapper_AB,
                                                         self.dht_model_A, self.dht_model_B, self.transition_model_B,
                                                         self.loss_fn_soft_dtw_AB)
            self.log(log_prefix + 'loss_action_mapper_AB', loss_action_mapper, on_step=False, on_epoch=True)
            return loss_action_mapper
        elif optimizer_idx == 5:
            loss_action_mapper = self.loss_action_mapper(batch["B"], self.trajectory_encoder_BZ, self.policy_ZA,
                                                         self.state_mapper_BA,
                                                         self.dht_model_B, self.dht_model_A, self.transition_model_A,
                                                         self.loss_fn_soft_dtw_BA)
            self.log(log_prefix + 'loss_action_mapper_BA', loss_action_mapper, on_step=False, on_epoch=True)
            return loss_action_mapper

    def configure_optimizers(self):
        """
            Helper function to generate all optimizers.
            Refer to pytorch lightning docs.
        """

        optimizer_transition_model_A = torch.optim.AdamW(self.transition_model_A.parameters(),
                                                         lr=self.hparams.transition_model_config.get("lr", 3e-4))
        optimizer_transition_model_B = torch.optim.AdamW(self.transition_model_B.parameters(),
                                                         lr=self.hparams.transition_model_config.get("lr", 3e-4))
        optimizer_state_mapper_AB = torch.optim.AdamW(self.state_mapper_AB.parameters(),
                                                      lr=self.hparams.state_mapper_config.get("lr", 3e-4))
        optimizer_state_mapper_BA = torch.optim.AdamW(self.state_mapper_BA.parameters(),
                                                      lr=self.hparams.state_mapper_config.get("lr", 3e-4))
        optimizer_action_mapper_AB = torch.optim.AdamW(chain(self.trajectory_encoder_AZ.parameters(),
                                                             self.policy_ZB.parameters()),
                                                       lr=self.hparams.action_mapper_config.get("lr", 3e-4))
        optimizer_action_mapper_BA = torch.optim.AdamW(chain(self.trajectory_encoder_BZ.parameters(),
                                                             self.policy_ZA.parameters()),
                                                       lr=self.hparams.action_mapper_config.get("lr", 3e-4))

        scheduler_state_mapper_AB = {"scheduler": ReduceLROnPlateau(optimizer_state_mapper_AB),
                                     "monitor": "validation_loss_state_mapper_AB",
                                     "name": "scheduler_optimizer_state_mapper_AB"
                                     }

        scheduler_state_mapper_BA = {"scheduler": ReduceLROnPlateau(optimizer_state_mapper_BA),
                                     "monitor": "validation_loss_state_mapper_BA",
                                     "name": "scheduler_optimizer_state_mapper_BA"
                                     }

        return [optimizer_transition_model_A, optimizer_transition_model_B,
                optimizer_state_mapper_AB, optimizer_state_mapper_BA,
                optimizer_action_mapper_AB, optimizer_action_mapper_BA], []
        # [scheduler_state_mapper_AB, scheduler_state_mapper_BA]


if __name__ == '__main__':
    from pytorch_lightning.loggers import WandbLogger
    from config import wandb_config
    import tempfile

    wandb_config.update(
        {
            "group": "tmp",
            # "mode": "disabled"
        }
    )

    mapper = LitDomainMapper

    config = {
        "transition_model_config": {
            "network_width": 256,
            "network_depth": 8,
            "dropout": .1,
            "out_activation": "tanh",
            "lr": 3e-3,
        },
        "state_mapper_config": {
            "network_width": 256,
            "network_depth": 8,
            "dropout": .1,
            "out_activation": "tanh",
            "lr": 3e-3,
        },
        "action_mapper_config": {
            "behavior_dim": 64,
            "encoder": {
                "lr": 3e-3,
                "d_model": 16,
                "nhead": 4,
                "num_layers": 2,
                "num_decoder_layers": 2,
                "dim_feedforward": 64,
            },
            "decoder": {
                "network_width": 256,
                "network_depth": 8,
                "dropout": .1,
                "out_activation": "tanh",
            },
        },

        "batch_size": 32,
        "max_epochs": 1_000,
    }

    domain_mapper = LitDomainMapper(
        data_file_A="panda_5_10_10.pt",
        data_file_B="ur5_5_10_10.pt",
        **config
    )

    wandb_logger = WandbLogger(**wandb_config, log_model=True)

    domain_mapper.configure_components(["t"])
    trainer = pl.Trainer(max_epochs=1, max_time="00:07:55:00",
                         accelerator="gpu", devices=-1, logger=wandb_logger)
    trainer.fit(domain_mapper)

    # trainer.save_checkpoint("../data/domain_mapper_dummy.chkp")
